spark {
  spark.app.name = "ALS"
  spark.executor.instances = 2
  spark.executor.cores = 1
  spark.executor.memory = "1g"

}

input {
  hdfs {
    result_table_name = "origin_movie"
    path = "hdfs://node02:9000/ml/data/sample_movielens_ratings.txt"
    format = "txt"
    separator = "::"
  }
}

transform {
  schema {
    fields = "userId:int,movieId:int,rating:float,timestamp:long"
    result_table_name = "new_movie"
  }

  split {
    weights = "0.8,0.2"
  }
}

train {
  ALSRecommendation {
    userCol = "userId"
    itemCol = "movieId"
    ratingCol = "rating"
    regParam = 0.1
    maxIter = 5
  }
}

model {

}

validate {
  regressionValidate {
    labelCol = "rating"
    predictionCol = "prediction"
    metricName = "rmse"
    modelType = "als"
  }
}

output {
  stdout {
    limit= 100
  }
}
