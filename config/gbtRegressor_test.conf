spark {
  spark.app.name = "Bronze"
  spark.executor.instances = 2
  spark.executor.cores = 1
  spark.executor.memory = "1g"

}

input {
  file {
    result_table_name = "sample_libsvm_data"
    path = "C:\\Users\\SV00242152\\Desktop\\fsdownload\\test.csv"
    format = "csv"
    header = true
  }
}

transform {
  typeConvert {
    colNames = "*"
    newType = "double"
  }
  vectorAssembler {
    inputCols = "slope2_avg,capa2,slope4_avg,slope2_mode,slope4_mode,slope2_max,slope4_max,processT2,voltage,envT_beg,envT_end,envT_avg"
    outputCol = "features"
  }
  minMaxScaler {
    inputCol = "features"
    outputCol = "scaledFeatures"
  }
  split {
    weights = "0.9, 0.1"
  }
}

train {
  gbtRegressor {
    maxDepth = 3
    maxIter = 200
    labelCol = "capa4"
    featuresCol = "scaledFeatures"
  }
}

model {
  saveModel {
    path = "hdfs://node02:9000/ml/model/libsvm/"
  }
}

validate {
  regressionValidate {
    labelCol = "capa4"
    modelType = "GBTRegression"
  }
}

predicate {
}

output {
  stdout {
    limit = 10
    columns = "capa4,prediction,features"
  }
}
