spark {
  spark.app.name = "Bronze"
  spark.executor.instances = 2
  spark.executor.cores = 1
  spark.executor.memory = "1g"

}

input {
  hdfs {
    result_table_name = "sample_libsvm_data"
    path = "hdfs://node02:9000/ml/data/waimai/waimai.csv"
    format = "csv"
    header = true
  }
}

transform {
  schema {
    fields = "label: Double, text: String"
  }
  tokenizer {
    inputCol = "text"
    outputCol = "words"
    type = "jieba"
  }
  hashingTF {
    inputCol = "words"
    outputCol = "rawFeatures"
  }
  tfidf {
    inputCol = "rawFeatures"
    outputCol = "features"
  }
  split {
    weights = "0.7, 0.3"
    seed = 1234
  }
}

train {
  multilayerPerceptronClassifier {
    labelCol = "label"
    featuresCol = "features"
    layers = "4, 5, 4, 3"
  }
}

model {
  saveModel {
    path = "hdfs://node02:9000/ml/model/waimai/"
  }
}

validate {
  multiClassificationValidate {
    modelType = "MultilayerPerceptronClassifier"
  }
}

output {
  stdout {
    limit = 10
    columns = "label, prediction, features"
  }
}
