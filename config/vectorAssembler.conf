spark {
  spark.app.name = "Bronze"
  spark.executor.instances = 2
  spark.executor.cores = 1
  spark.executor.memory = "1g"

}

input {
  file {
      result_table_name = "test_data"
      path = "/C:\\Users\\SV00242152\\Desktop\\test.csv"
      format = "csv",
      header = true
    }
}

transform {
  schema {
    fields = "color:String,lab:String,value1:Double,value2:Double"
    result_table_name = "test"
  }
  vectorAssembler {
    inputCols = "value1, value2"
    outputCol = "output"
  }
}

ml {

}

output {
  stdout {
    limit= 10
  }

  # you can also you other output plugins, such as sql
  # hdfs {
  #   path = "hdfs://hadoop-cluster-01/nginx/accesslog_processed"
  #   save_mode = "append"
  # }
}
