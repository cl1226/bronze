spark {
  spark.app.name = "LinearRegression_fangjia"
  spark.executor.instances = 2
  spark.executor.cores = 1
  spark.executor.memory = "1g"

}

input {
  file {
    result_table_name = "origin_fangjia"
    path = "/C:\\Users\\SV00242152\\Desktop\\kc_train.csv"
    format = "csv"
    separator = ","
    header = false
  }
}

transform {
  schema {
    fields = "c1:double,c2:double,c3:double,c4:double,c5:double,c6:double,c7:double,c8:double,c9:double,c10:double,c11:double,c12:double,c13:double,c14:double"
  }
  labeledPoint {
    labelCol = "c2"
    featuresCol = "c1,c3,c4,c5,c6,c7,c8,c9,c10,c11,c12,c13,c14"
  }
  minMaxScaler {
    inputCol = "features"
    outputCol = "scaledFeatures"
  }
  split {
    weights = "0.8, 0.2"
  }
}

train {
  linearRegression {
    labelCol = "label"
    featuresCol = "scaledFeatures"
  }
}

model {
  saveModel {
    path = "hdfs://node02:9000/ml/model/linearRegression/"
  }
}

validate {
  linearRegressionValidate {
  }
}

output {
  stdout {
    limit = 10
    columns = "label,prediction,features"
  }
}
