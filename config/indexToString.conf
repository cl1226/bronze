spark {
  spark.app.name = "Bronze"
  spark.executor.instances = 2
  spark.executor.cores = 1
  spark.executor.memory = "1g"

}

input {
  hdfs {
    result_table_name = "iris_origin"
    path = "hdfs://node02:9000/ml/lr_data/iris.csv"
    format = "csv"
  }
}

transform {
  schema {
    fields = "calyxLength:Double,calyxWidth:Double,petalLength:Double,petalWidth:Double,classification:String"
    result_table_name = "iris"
  }

  #sql {
  #  sql = "select * from iris where classification <> 'Iris-setosa'"
  #}

  stringIndexer {
    inputCol = "classification"
    outputCol = "category"
    handleInvalid = "error"
  }

  indexToString {
    inputCol = "category"
    outputCol = "category_index"
  }
}

ml {
}

output {
  stdout {
    limit= 10
  }

  # you can also you other output plugins, such as sql
  # hdfs {
  #   path = "hdfs://hadoop-cluster-01/nginx/accesslog_processed"
  #   save_mode = "append"
  # }
}
