spark {
  spark.app.name = "Bronze"
  spark.executor.instances = 2
  spark.executor.cores = 1
  spark.executor.memory = "1g"

}

input {
  file {
    result_table_name = "test_data"
    path = "/C:\\Users\\SV00242152\\Desktop\\test2.csv"
    format = "csv",
    header = true
  }
}

transform {
  tokenizer {
    inputCol = "text"
    outputCol = "features"
  }
  stopWordsRemover {
    inputCol = "features"
    outputCol = "filtered"
  }
  nGram {
    inputCol = "filtered"
    outputCol = "ngram_out"
    count = 3
  }
}

ml {

}

output {
  stdout {
    limit= 10
  }

  # you can also you other output plugins, such as sql
  # hdfs {
  #   path = "hdfs://hadoop-cluster-01/nginx/accesslog_processed"
  #   save_mode = "append"
  # }
}
